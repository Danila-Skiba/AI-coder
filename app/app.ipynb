{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e74e6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "from langchain_gigachat.embeddings.gigachat import GigaChatEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pathlib import Path\n",
    "from vectorization.v_a_c import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4238097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"MjQxYzdhYjQtZjk5OC00ZjUzLWJjZTYtZGMyOGJhNGQ1OGFmOmUzNTA0Mjg4LWQ5NGEtNDdhNy1hNDkzLTgwNjczZTFjMGE1YQ==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0bcd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DIR = Path(\"..\\\\data\\\\code_prod\")\n",
    "DOC_DIR = Path(\"..\\\\data\\\\documentation_prod\")\n",
    "VECTOR_STORE_PATH = \"langchain_vector_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "144fbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE_DIR = Path(\"..\\\\data\\\\code\")\n",
    "# DOC_DIR = Path(\"..\\\\data\\\\documentation\")\n",
    "# VECTOR_STORE_PATH = \"langchain_vector_store_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "750a67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': False}\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=model_name,\n",
    "#                                   model_kwargs=model_kwargs,\n",
    "#                                   encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a10ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=GigaChatEmbeddings(\n",
    "        credentials=API_KEY,\n",
    "        scope=\"GIGACHAT_API_PERS\",\n",
    "        verify_ssl_certs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "072f5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SmartCodeDocSystem(embeddings, chunk_size=600, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a53e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка и обработка файлов...\n",
      "Обработка кода из ..\\data\\code_prod\n",
      "  Обработано 10/1586 файлов кода\n",
      "  Обработано 20/1586 файлов кода\n",
      "  Обработано 30/1586 файлов кода\n",
      "  Обработано 40/1586 файлов кода\n",
      "  Обработано 50/1586 файлов кода\n",
      "  Обработано 60/1586 файлов кода\n",
      "  Обработано 70/1586 файлов кода\n",
      "  Обработано 80/1586 файлов кода\n",
      "  Обработано 90/1586 файлов кода\n",
      "  Обработано 100/1586 файлов кода\n",
      "  Обработано 110/1586 файлов кода\n",
      "  Обработано 120/1586 файлов кода\n",
      "  Обработано 130/1586 файлов кода\n",
      "  Обработано 140/1586 файлов кода\n",
      "  Обработано 150/1586 файлов кода\n",
      "  Обработано 160/1586 файлов кода\n",
      "  Обработано 170/1586 файлов кода\n",
      "  Обработано 180/1586 файлов кода\n",
      "  Обработано 190/1586 файлов кода\n",
      "  Обработано 200/1586 файлов кода\n",
      "  Обработано 210/1586 файлов кода\n",
      "  Обработано 220/1586 файлов кода\n",
      "  Обработано 230/1586 файлов кода\n",
      "  Обработано 240/1586 файлов кода\n",
      "  Обработано 250/1586 файлов кода\n",
      "  Обработано 260/1586 файлов кода\n",
      "  Обработано 270/1586 файлов кода\n",
      "  Обработано 280/1586 файлов кода\n",
      "  Обработано 290/1586 файлов кода\n",
      "  Обработано 300/1586 файлов кода\n",
      "  Обработано 310/1586 файлов кода\n",
      "  Обработано 320/1586 файлов кода\n",
      "  Обработано 330/1586 файлов кода\n",
      "  Обработано 340/1586 файлов кода\n",
      "  Обработано 350/1586 файлов кода\n",
      "  Обработано 360/1586 файлов кода\n",
      "  Обработано 370/1586 файлов кода\n",
      "  Обработано 380/1586 файлов кода\n",
      "  Обработано 390/1586 файлов кода\n",
      "  Обработано 400/1586 файлов кода\n",
      "  Обработано 410/1586 файлов кода\n",
      "  Обработано 420/1586 файлов кода\n",
      "  Обработано 430/1586 файлов кода\n",
      "  Обработано 440/1586 файлов кода\n",
      "  Обработано 450/1586 файлов кода\n",
      "  Обработано 460/1586 файлов кода\n",
      "  Обработано 470/1586 файлов кода\n",
      "  Обработано 480/1586 файлов кода\n",
      "  Обработано 490/1586 файлов кода\n",
      "  Обработано 500/1586 файлов кода\n",
      "  Обработано 510/1586 файлов кода\n",
      "  Обработано 520/1586 файлов кода\n",
      "  Обработано 530/1586 файлов кода\n",
      "  Обработано 540/1586 файлов кода\n",
      "  Обработано 550/1586 файлов кода\n",
      "  Обработано 560/1586 файлов кода\n",
      "  Обработано 570/1586 файлов кода\n",
      "  Обработано 580/1586 файлов кода\n",
      "  Обработано 590/1586 файлов кода\n",
      "  Обработано 600/1586 файлов кода\n",
      "  Обработано 610/1586 файлов кода\n",
      "  Обработано 620/1586 файлов кода\n",
      "  Обработано 630/1586 файлов кода\n",
      "  Обработано 640/1586 файлов кода\n",
      "Ошибка при чтении ..\\data\\code_prod\\non-utf8-encoding.py: 'utf-8' codec can't decode byte 0xb1 in position 23: invalid start byte\n",
      "  Обработано 650/1586 файлов кода\n",
      "  Обработано 660/1586 файлов кода\n",
      "  Обработано 670/1586 файлов кода\n",
      "  Обработано 680/1586 файлов кода\n",
      "  Обработано 690/1586 файлов кода\n",
      "  Обработано 700/1586 файлов кода\n",
      "  Обработано 710/1586 файлов кода\n",
      "  Обработано 720/1586 файлов кода\n",
      "  Обработано 730/1586 файлов кода\n",
      "  Обработано 740/1586 файлов кода\n",
      "  Обработано 750/1586 файлов кода\n",
      "  Обработано 760/1586 файлов кода\n",
      "  Обработано 770/1586 файлов кода\n",
      "  Обработано 780/1586 файлов кода\n",
      "  Обработано 790/1586 файлов кода\n",
      "  Обработано 800/1586 файлов кода\n",
      "  Обработано 810/1586 файлов кода\n",
      "  Обработано 820/1586 файлов кода\n",
      "  Обработано 830/1586 файлов кода\n",
      "  Обработано 840/1586 файлов кода\n",
      "  Обработано 850/1586 файлов кода\n",
      "  Обработано 860/1586 файлов кода\n",
      "  Обработано 870/1586 файлов кода\n",
      "  Обработано 880/1586 файлов кода\n",
      "  Обработано 890/1586 файлов кода\n",
      "  Обработано 900/1586 файлов кода\n",
      "  Обработано 910/1586 файлов кода\n",
      "  Обработано 920/1586 файлов кода\n",
      "  Обработано 930/1586 файлов кода\n",
      "  Обработано 940/1586 файлов кода\n",
      "  Обработано 950/1586 файлов кода\n",
      "  Обработано 960/1586 файлов кода\n",
      "  Обработано 970/1586 файлов кода\n",
      "  Обработано 980/1586 файлов кода\n",
      "  Обработано 990/1586 файлов кода\n",
      "  Обработано 1000/1586 файлов кода\n",
      "  Обработано 1010/1586 файлов кода\n",
      "  Обработано 1020/1586 файлов кода\n",
      "  Обработано 1030/1586 файлов кода\n",
      "  Обработано 1040/1586 файлов кода\n",
      "  Обработано 1050/1586 файлов кода\n",
      "  Обработано 1060/1586 файлов кода\n",
      "  Обработано 1070/1586 файлов кода\n",
      "  Обработано 1080/1586 файлов кода\n",
      "  Обработано 1090/1586 файлов кода\n",
      "  Обработано 1100/1586 файлов кода\n",
      "  Обработано 1110/1586 файлов кода\n",
      "  Обработано 1120/1586 файлов кода\n",
      "  Обработано 1130/1586 файлов кода\n",
      "  Обработано 1140/1586 файлов кода\n",
      "  Обработано 1150/1586 файлов кода\n",
      "  Обработано 1160/1586 файлов кода\n",
      "  Обработано 1170/1586 файлов кода\n",
      "  Обработано 1180/1586 файлов кода\n",
      "  Обработано 1190/1586 файлов кода\n",
      "  Обработано 1200/1586 файлов кода\n",
      "  Обработано 1210/1586 файлов кода\n",
      "  Обработано 1220/1586 файлов кода\n",
      "  Обработано 1230/1586 файлов кода\n",
      "  Обработано 1240/1586 файлов кода\n",
      "  Обработано 1250/1586 файлов кода\n",
      "  Обработано 1270/1586 файлов кода\n",
      "  Обработано 1280/1586 файлов кода\n",
      "  Обработано 1290/1586 файлов кода\n",
      "  Обработано 1300/1586 файлов кода\n",
      "  Обработано 1310/1586 файлов кода\n",
      "  Обработано 1320/1586 файлов кода\n",
      "  Обработано 1330/1586 файлов кода\n",
      "  Обработано 1340/1586 файлов кода\n",
      "  Обработано 1350/1586 файлов кода\n",
      "  Обработано 1370/1586 файлов кода\n",
      "  Обработано 1380/1586 файлов кода\n",
      "  Обработано 1390/1586 файлов кода\n",
      "  Обработано 1410/1586 файлов кода\n",
      "  Обработано 1420/1586 файлов кода\n",
      "  Обработано 1430/1586 файлов кода\n",
      "  Обработано 1440/1586 файлов кода\n",
      "  Обработано 1460/1586 файлов кода\n",
      "  Обработано 1510/1586 файлов кода\n",
      "  Обработано 1530/1586 файлов кода\n",
      "  Обработано 1540/1586 файлов кода\n",
      "  Обработано 1550/1586 файлов кода\n",
      "  Обработано 1560/1586 файлов кода\n",
      "  Обработано 1570/1586 файлов кода\n",
      "  Обработано 1580/1586 файлов кода\n",
      "Загружено 1586 файлов кода\n",
      "Обработка документации из ..\\data\\documentation_prod\n",
      "  Обработано 5/218 файлов документации\n",
      "  Обработано 10/218 файлов документации\n",
      "  Обработано 15/218 файлов документации\n",
      "  Обработано 20/218 файлов документации\n",
      "  Обработано 25/218 файлов документации\n",
      "  Обработано 30/218 файлов документации\n",
      "  Обработано 35/218 файлов документации\n",
      "  Обработано 40/218 файлов документации\n",
      "  Обработано 45/218 файлов документации\n",
      "  Обработано 50/218 файлов документации\n",
      "  Обработано 55/218 файлов документации\n",
      "  Обработано 60/218 файлов документации\n",
      "  Обработано 65/218 файлов документации\n",
      "  Обработано 70/218 файлов документации\n",
      "  Обработано 75/218 файлов документации\n",
      "  Обработано 80/218 файлов документации\n",
      "  Обработано 85/218 файлов документации\n",
      "  Обработано 90/218 файлов документации\n",
      "  Обработано 95/218 файлов документации\n",
      "  Обработано 100/218 файлов документации\n",
      "  Обработано 105/218 файлов документации\n",
      "  Обработано 110/218 файлов документации\n",
      "  Обработано 115/218 файлов документации\n",
      "  Обработано 120/218 файлов документации\n",
      "  Обработано 125/218 файлов документации\n",
      "  Обработано 130/218 файлов документации\n",
      "  Обработано 135/218 файлов документации\n",
      "  Обработано 140/218 файлов документации\n",
      "  Обработано 145/218 файлов документации\n",
      "  Обработано 150/218 файлов документации\n",
      "  Обработано 155/218 файлов документации\n",
      "  Обработано 160/218 файлов документации\n",
      "  Обработано 165/218 файлов документации\n",
      "  Обработано 170/218 файлов документации\n",
      "  Обработано 175/218 файлов документации\n",
      "  Обработано 180/218 файлов документации\n",
      "  Обработано 185/218 файлов документации\n",
      "  Обработано 190/218 файлов документации\n",
      "  Обработано 195/218 файлов документации\n",
      "  Обработано 200/218 файлов документации\n",
      "  Обработано 205/218 файлов документации\n",
      "  Обработано 210/218 файлов документации\n",
      "  Обработано 215/218 файлов документации\n",
      "Загружено 218 файлов документации\n",
      "Всего создано 17224 чанков\n",
      "  - Код: 7184\n",
      "  - Документация: 10040\n",
      "Создание векторного хранилища...\n",
      "Сохранение в langchain_vector_store\n",
      "Векторное хранилище создано и сохранено\n"
     ]
    }
   ],
   "source": [
    "documents = system.load_and_process_files(CODE_DIR, DOC_DIR)\n",
    "\n",
    "system.create_vector_store(VECTOR_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d04605c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка векторного хранилища из langchain_vector_store\n",
      "Векторное хранилище загружено\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.load_vector_store(VECTOR_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dff123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GigaChat(\n",
    "    credentials=API_KEY,\n",
    "    verify_ssl_certs=False,\n",
    ")\n",
    "\n",
    "smart_retriever = SmartRetriever(smart_system=system, k=3)\n",
    "\n",
    "prompt = create_smart_prompt()\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "retrieval_chain = create_retrieval_chain(smart_retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c8da407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ:\n",
      "### Как использовать FAISS векторный магазин в LangChain?\n",
      "\n",
      "В библиотеке LangChain можно использовать векторные магазины для хранения и управления векторами слов, которые представляют собой представления слов в пространстве многомерных векторов. Одним из популярных библиотек для индексации и поиска подобных векторов является **FAISS** (Facebook AI Similarity Search). В данном контексте мы рассмотрим, как создать экземпляр FAISS векторного магазина и интегрировать его с LangChain для выполнения задач поиска.\n",
      "\n",
      "#### Пример использования FAISS в LangChain\n",
      "\n",
      "Для начала вам потребуется установить необходимые зависимости:\n",
      "\n",
      "```bash\n",
      "%pip install --upgrade --quiet  langchain-openai faiss-cpu  \n",
      "```\n",
      "\n",
      "Затем можно приступить к созданию экземпляра FAISS векторного магазина.\n",
      "\n",
      "```python\n",
      "from langchain_community.vectorstores import FAISS\n",
      "\n",
      "# Создание FAISS векторного магазина\n",
      "faiiss = FAISS()\n",
      "\n",
      "# Добавление данных в векторный магазин\n",
      "documents = [\"This is a test document\", \"Another test document\"]\n",
      "vectors = faiiss.embed_documents(documents)\n",
      "\n",
      "# Поиск похожих документов\n",
      "similar_documents = faiiss.find_similar(vectors[0])\n",
      "print(\"Similar documents:\", similar_documents)\n",
      "```\n",
      "\n",
      "### Объяснение кода\n",
      "\n",
      "1. **Импорт модулей**: Для создания векторного магазина используется класс `FAISS` из пакета `langchain_community.vectorstores`. Этот пакет предоставляет различные реализации векторных магазинов.\n",
      "\n",
      "2. **Создание FAISS векторного магазина**: После импорта класса создается объект `faiiss`, который представляет собой экземпляр FAISS векторного магазина.\n",
      "\n",
      "3. **Добавление данных в векторный магазин**: Метод `embed_documents` принимает список документов и возвращает соответствующие им векторы. Эти векторы будут храниться в векторном магазине.\n",
      "\n",
      "4. **Поиск похожих документов**: Метод `find_similar` позволяет искать документы, наиболее близкие к заданному вектору. В этом примере функция ищет документ, наиболее похожий на первый добавленный вектор.\n",
      "\n",
      "### Дополнительная информация\n",
      "\n",
      "LangChain поддерживает интеграцию с различными векторными магазинами через интерфейс `VectorStore`. Это позволяет легко переключаться между разными технологиями хранения и обработки векторов. Например, можно использовать другие векторные магазины, такие как `ElasticVectorSearch`, если требуется работа с большими объемами данных или интеграция с другими системами поиска.\n",
      "\n",
      "Таким образом, использование FAISS совместно с LangChain дает возможность эффективно работать с семантическими векторами и выполнять задачи поиска на основе этих векторов.\n",
      "\n",
      "ИНФО О ПОИСКЕ:\n",
      "Тип поиска: doc-first\n",
      "Найдено документов: 3\n",
      "Код: 1, Документация: 2\n"
     ]
    }
   ],
   "source": [
    "query = \"How to use FAISS vectorstore in LangChain?\"\n",
    "\n",
    "try:\n",
    "    response = retrieval_chain.invoke({\"input\": query})\n",
    "    \n",
    "    print(\"ОТВЕТ:\")\n",
    "    print(response[\"answer\"])\n",
    "    \n",
    "    search_result = system.smart_search(query, k=3)\n",
    "    print(f\"\\nИНФО О ПОИСКЕ:\")\n",
    "    print(f\"Тип поиска: {search_result.search_type}\")\n",
    "    print(f\"Найдено документов: {len(search_result.documents)}\")\n",
    "    \n",
    "    code_count = len([d for d in search_result.documents if d.metadata.get('type') == 'code'])\n",
    "    doc_count = len([d for d in search_result.documents if d.metadata.get('type') == 'doc'])\n",
    "    print(f\"Код: {code_count}, Документация: {doc_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
