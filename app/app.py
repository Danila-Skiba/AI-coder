import streamlit as st
import os
from pathlib import Path
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from langchain.vectorstores.faiss import FAISS
from langchain_core.documents import Document
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_gigachat.chat_models import GigaChat
from langchain_gigachat.embeddings.gigachat import GigaChatEmbeddings
import chardet
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document


st.set_page_config(
    page_title="LangChain RAG Assistant",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ LangChain RAG Assistant")
st.markdown("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ LangChain")

API_KEY = os.getenv("GIGACHAT_API_KEY", "YjllY2FhYjgtNGRlMC00MDA4LWIwZmYtNjdlNjY0ZmI5OTc4OmRkMjZhOWFjLThhNTctNGM3ZC1iZjFkLWQ3NGY1NmRjNTQzMQ==")
DOC_PATH = "../data/documentation"
CODE_PATH = "../data/code"

DOC_CHUNK_SIZE = 1000
DOC_CHUNK_OVERLAP = 200
CODE_CHUNK_SIZE = 500
CODE_CHUNK_OVERLAP = 100
K_DOCUMENTS = 5

def detect_encoding(file_path):
    with open(file_path, 'rb') as f:
        raw_data = f.read(10000)
    result = chardet.detect(raw_data)
    return result['encoding']

def safe_read_text(path):
    encoding = detect_encoding(path)
    return Path(path).read_text(encoding=encoding, errors="ignore")

@st.cache_resource
def initialize_rag_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    try:
        doc_files = list(Path(DOC_PATH).rglob("*.md"))[:3]
        code_files = list(Path(CODE_PATH).rglob("*.py"))[:3]
        
        if not doc_files and not code_files:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã")
            return None, None
        
        doc_splitter = RecursiveCharacterTextSplitter(
            chunk_size=DOC_CHUNK_SIZE, 
            chunk_overlap=DOC_CHUNK_OVERLAP
        )
        code_splitter = RecursiveCharacterTextSplitter(
            separators=["\nclass", "\ndef", "\n"], 
            chunk_size=CODE_CHUNK_SIZE, 
            chunk_overlap=CODE_CHUNK_OVERLAP
        )
        
        docs = []
        for file in doc_files:
            try:
                content = safe_read_text(file)
                chunks = doc_splitter.split_text(content)
                for chunk in chunks:
                    docs.append(Document(
                        page_content=chunk, 
                        metadata={"source": "doc", "file": str(file.name)}
                    ))
            except Exception as e:
                st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        
        code_docs = []
        for file in code_files:
            try:
                content = safe_read_text(file)
                chunks = code_splitter.split_text(content)
                for chunk in chunks:
                    code_docs.append(Document(
                        page_content=chunk, 
                        metadata={"source": "code", "file": str(file.name)}
                    ))
            except Exception as e:
                st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–¥–∞: {e}")
        
        documents = docs + code_docs
        
        if not documents:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")
            return None, None
        
        embedding = GigaChatEmbeddings(
            credentials=API_KEY,
            scope="GIGACHAT_API_PERS",
            verify_ssl_certs=False,
        )
        
        vector_store = FAISS.from_documents(documents, embedding=embedding)
        retriever = vector_store.as_retriever(search_kwargs={"k": K_DOCUMENTS})
        
        llm = GigaChat(
            credentials=API_KEY,
            verify_ssl_certs=False,
        )
        
        prompt = ChatPromptTemplate.from_template('''–¢—ã ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫, —Ä–∞–±–æ—Ç–∞—é—â–∏–π —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π LangChain. –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–æ–¥—É –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é, –∏ –∫–æ–¥. –°–ª–µ–¥—É–π —ç—Ç–∏–º –ø—Ä–∞–≤–∏–ª–∞–º:

---

1. üìÑ –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–∑—è—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, —É–∫–∞–∂–∏, –∏–∑ –∫–∞–∫–æ–≥–æ –∏–º–µ–Ω–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ–Ω–∞ –±—ã–ª–∞ –ø–æ–ª—É—á–µ–Ω–∞. –ü—Ä–∏–º–µ—Ä:  
   _"–°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (load_chain.md)..."_

2. üß© –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–∑—è—Ç–∞ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞, —É–∫–∞–∂–∏, –∏–∑ –∫–∞–∫–æ–≥–æ —Ñ–∞–π–ª–∞ –æ–Ω–∞ –±—ã–ª–∞ –ø–æ–ª—É—á–µ–Ω–∞. –ü—Ä–∏–º–µ—Ä:  
   _"–í –∫–æ–¥–µ (loader.py) —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ —Ç–æ–ª—å–∫–æ —Ü–µ–ø–æ—á–∫–∞ summarize_chain..."_

3. ‚ö†Ô∏è –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –∫–æ–¥ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –¥—Ä—É–≥ –¥—Ä—É–≥—É, –≤—Å—ë —Ä–∞–≤–Ω–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç, –Ω–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏ –æ–± —ç—Ç–æ–º. –ü—Ä–∏–º–µ—Ä:  
   _"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (load_chain.md) —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç, —á—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è 3 —Ü–µ–ø–æ—á–∫–∏, –æ–¥–Ω–∞–∫–æ –≤ –∫–æ–¥–µ (loader.py) —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞. –≠—Ç–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ."_

4. ‚ùì –ï—Å–ª–∏ —Ç—ã –Ω–µ —É–≤–µ—Ä–µ–Ω, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–¥—É, —Ç–∞–∫–∂–µ –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏ –æ–± —ç—Ç–æ–º. –ü—Ä–∏–º–µ—Ä:  
   _"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (agent_overview.md) —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞ (agent/base.py). –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã."_

5. üí¨ –ò–∑–±–µ–≥–∞–π –≤—ã–º—ã—à–ª–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π ‚Äî –≤—Å–µ —Ñ–∞–∫—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏ –∏–∑ –∫–æ–¥–∞ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

---

–í –∫–æ–Ω—Ü–µ –æ—Ç–≤–µ—Ç–∞ —Å–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ:
- –£–∫–∞–∑–∞–Ω –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–∞–∂–¥–æ–≥–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è?
- –ï—Å—Ç—å –ª–∏ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è?

---

–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {input}''')
        
        document_chain = create_stuff_documents_chain(
            llm=llm,
            prompt=prompt
        )
        
        retrieval_chain = create_retrieval_chain(retriever, document_chain)
        
        return retrieval_chain, len(documents)
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã: {e}")
        return None, None

def main():
    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã..."):
        retrieval_chain, doc_count = initialize_rag_system()
    
    if retrieval_chain:
        st.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        
        with st.expander("üìù –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤"):
            example_questions = [
                "What is LangSmith?",
                "–ö–∞–∫ –∞–≥–µ–Ω—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ, —á—Ç–æ –¥–µ–ª–∞—Ç—å?",
                "–ö–∞–∫–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç LangChain?",
                "–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—É—é —Ü–µ–ø–æ—á–∫—É –≤ load_chain?",
                "–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ü–µ–ø–æ—á–∫—É?",
                "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PromptTemplate?",
                "–ü—Ä–∏–≤–µ–¥–∏ –ø—Ä–∏–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏",
                "–ö–∞–∫–∏–µ –æ—à–∏–±–∫–∏ –±—ã–≤–∞—é—Ç –≤ LangChain –∏ –∫–æ–≥–¥–∞ –æ–Ω–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç?"
            ]
            
            for i, example in enumerate(example_questions):
                if st.button(f"üìå {example}", key=f"example_{i}"):
                    st.session_state.user_question = example
        
        user_question = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
            value=st.session_state.get('user_question', ''),
            height=100,
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –≤ LangChain?"
        )
        
        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            ask_button = st.button("üöÄ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", type="primary")
        with col2:
            clear_button = st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å")
        
        if clear_button:
            st.session_state.user_question = ''
            st.rerun()
        
        if ask_button and user_question.strip():
            with st.spinner("üîç –ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
                try:
                    response = retrieval_chain.invoke({'input': user_question})
                    
                    st.markdown("---")
                    st.subheader("ü§ñ –û—Ç–≤–µ—Ç")
                    st.markdown(response['answer'])
                    
                    with st.expander("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"):
                        for i, doc in enumerate(response['context']):
                            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}:**")
                            st.markdown(f"- **–¢–∏–ø:** {'–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è' if doc.metadata.get('source') == 'doc' else '–ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥'}")
                            if 'file' in doc.metadata:
                                st.markdown(f"- **–§–∞–π–ª:** {doc.metadata['file']}")
                            st.markdown(f"- **–§—Ä–∞–≥–º–µ–Ω—Ç:**")
                            st.code(doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content)
                            st.markdown("---")
                    
                except Exception as e:
                    st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
                    st.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")
        
        elif ask_button:
            st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
    
    else:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")

if 'user_question' not in st.session_state:
    st.session_state.user_question = ''

with st.sidebar:
    st.markdown("### ‚ÑπÔ∏è –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
    st.markdown("""
    –≠—Ç–æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ LangChain.
    
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
    - –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ LangChain
    - –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    - –£–∫–∞–∑–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    - –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π –∏ –∫–æ–¥–æ–º
    
    –ü—Ä–æ—Å—Ç–æ –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç!
    """)
    
    st.markdown("---")
    st.markdown("**üí° –°–æ–≤–µ—Ç:** –§–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.")

if __name__ == "__main__":
    main()
