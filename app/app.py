import streamlit as st
import os
from pathlib import Path
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_gigachat.chat_models import GigaChat
from langchain_gigachat.embeddings.gigachat import GigaChatEmbeddings
from langchain.embeddings import HuggingFaceEmbeddings
from vectorization.v_a_c import SmartCodeDocSystem, SmartRetriever, create_smart_prompt
import os

from dotenv import load_dotenv
load_dotenv()


st.set_page_config(
    page_title="LangChain RAG Assistant",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("LangChain RAG Assistant")
st.markdown("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ LangChain")

API_KEY = os.getenv("GIGACHAT_CREDENTIALS")
VECTOR_STORE_PATH = os.path.join(os.path.dirname(__file__), "langchain_vector_store")


@st.cache_resource
def initialize_rag_system():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    try:
        embeddings = GigaChatEmbeddings(
            credentials=API_KEY,
            scope="GIGACHAT_API_PERS",
            verify_ssl_certs=False,
        )

        system = SmartCodeDocSystem(embeddings, chunk_size=600, chunk_overlap=100)
        
        system.load_vector_store(VECTOR_STORE_PATH)

        llm = GigaChat(
            credentials=API_KEY,
            verify_ssl_certs=False,
            model="GigaChat-Pro"
        )

        smart_retriever = SmartRetriever(smart_system=system, k=150)
        prompt = create_smart_prompt()
        document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)
        retrieval_chain = create_retrieval_chain(smart_retriever, document_chain)

        return retrieval_chain, system

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã: {e}")
        return None, None

def main():
    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã..."):
        retrieval_chain, system = initialize_rag_system()

    if retrieval_chain and system:
        st.success("–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

        with st.expander("–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤"):
            example_questions = [
                "How to use FAISS vectorstore in LangChain?",
                "What is LangSmith?",
                "–ö–∞–∫–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç LangChain?",
                "–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Ü–µ–ø–æ—á–∫—É?",
                "–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PromptTemplate?"
            ]

            for i, example in enumerate(example_questions):
                if st.button(f"{example}", key=f"example_{i}"):
                    st.session_state.user_question = example

        user_question = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
            value=st.session_state.get('user_question', ''),
            height=100,
            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: How to use FAISS vectorstore in LangChain?"
        )

        col1, col2, col3 = st.columns([1, 1, 4])
        with col1:
            ask_button = st.button("–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å", type="primary")

        if ask_button and user_question.strip():
            with st.spinner("–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
                try:
                    response = retrieval_chain.invoke({'input': user_question})

                    search_result = system.smart_search(user_question, k=150)

                    st.markdown("---")
                    st.subheader("–û—Ç–≤–µ—Ç")
                    st.markdown(response['answer'])

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("–¢–∏–ø –ø–æ–∏—Å–∫–∞", search_result.search_type)
                    with col2:
                        code_count = len([d for d in search_result.documents if d.metadata.get('type') == 'code'])
                        st.metric("–î–æ–∫—É–º–µ–Ω—Ç—ã –∫–æ–¥–∞", code_count)
                    with col3:
                        doc_count = len([d for d in search_result.documents if d.metadata.get('type') == 'doc'])
                        st.metric("–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", doc_count)

                    with st.expander("–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"):
                        for i, doc in enumerate(response['context']):
                            st.markdown(f"**–ò—Å—Ç–æ—á–Ω–∏–∫ {i + 1}:**")

                            doc_type = doc.metadata.get('type', 'unknown')
                            if doc_type == 'code':
                                st.markdown(f"- **–¢–∏–ø:** –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥")
                            elif doc_type == 'doc':
                                st.markdown(f"- **–¢–∏–ø:** –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")
                            else:
                                st.markdown(f"- **–¢–∏–ø:** –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

                            if 'file' in doc.metadata:
                                st.markdown(f"- **–§–∞–π–ª:** {doc.metadata['file']}")

                            if 'source' in doc.metadata:
                                st.markdown(f"- **–ò—Å—Ç–æ—á–Ω–∏–∫:** {doc.metadata['source']}")

                            st.markdown(f"- **–§—Ä–∞–≥–º–µ–Ω—Ç:**")
                            content_preview = doc.page_content[:400] + "..." if len(
                                doc.page_content) > 400 else doc.page_content
                            st.code(content_preview, language="python" if doc_type == 'code' else "markdown")
                            st.markdown("---")

                    with st.expander("–î–µ—Ç–∞–ª–∏ –ø–æ–∏—Å–∫–∞"):
                        st.markdown(f"**–¢–∏–ø –ø–æ–∏—Å–∫–∞:** {search_result.search_type}")
                        st.markdown(f"**–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {len(search_result.documents)}")

                        if hasattr(search_result, 'scores') and search_result.scores:
                            st.markdown("**–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**")
                            for i, score in enumerate(search_result.scores):
                                st.progress(min(score, 1.0), text=f"–î–æ–∫—É–º–µ–Ω—Ç {i + 1}: {score:.3f}")

                except Exception as e:
                    st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
                    st.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É")

                    with st.expander("–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                        st.code(str(e))

        elif ask_button:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")

    else:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        st.error("- –ù–∞–ª–∏—á–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–æ –ø—É—Ç–∏: " + VECTOR_STORE_PATH)
        st.error("- –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ GigaChat")
        st.error("- –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥—É–ª—è vectorization.v_a_c")


if 'user_question' not in st.session_state:
    st.session_state.user_question = ''

with st.sidebar:
    st.markdown("### –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
    st.markdown("""
    –≠—Ç–æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ LangChain.
    
    –ü—Ä–æ—Å—Ç–æ –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç!
    """)

    st.markdown("---")
    st.markdown("**–°–æ–≤–µ—Ç:** –§–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.")

if __name__ == "__main__":
    main()
